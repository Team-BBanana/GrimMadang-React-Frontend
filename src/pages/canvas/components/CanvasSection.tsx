import { fabric } from "fabric";
import { useEffect, useRef, useState } from "react";
import { useAtom } from "jotai";
import canvasInstanceAtom from "@/pages/canvas/components/stateCanvasInstance";
import BannerSection from "@/pages/canvas/components/BannerSection.tsx";
import style from "../CanvasPage.module.css";
import API from "@/api";
import ImagePanelSection from "./PanelSection";
import FeedbackSection from "./FeedbackSection";
import { makeFrame } from '../utils/makeFrame';
import debounce from 'lodash/debounce';
import { useAudio } from '@/context/AudioContext';
import Overlay from './Overlay';

interface CanvasSectionProps {
  className?: string;
  onUpload: (dataURL: string, step: number) => void;
  canvasRef: React.RefObject<HTMLCanvasElement>;
  onChange: () => void;
  feedbackData: any;
  onFinalSave?: () => void;
}

const CanvasSection = ({ onUpload, canvasRef, onChange, onFinalSave }: CanvasSectionProps) => {
  const canvasContainerRef = useRef<HTMLDivElement>(null);
  const [canvas, setCanvas] = useAtom(canvasInstanceAtom);
  const [isDragging, setIsDragging] = useState(true);
  const [step, setStep] = useState(1);
  const [isPanelVisible, setIsPanelVisible] = useState(false);
  const [brushWidth] = useState(10);

  const [imageData, setImageData] = useState<any>(null);
  const [currentFeedback, setCurrentFeedback] = useState<any>(null);
  const [isImageCardCollapsed, setIsImageCardCollapsed] = useState(false);
  const [isFeedbackCardCollapsed, setIsFeedbackCardCollapsed] = useState(false);

  const [currentAudioIndex, setCurrentAudioIndex] = useState(0);
  const [playedAudios, setPlayedAudios] = useState<Set<number>>(new Set());
  const { dispatch, state } = useAudio();
  const { isPlaying } = state;

  const [overlay, setOverlay] = useState<string | null>(null);

  const [currentPlayingFile, setCurrentPlayingFile] = useState<string | null>(null);

  const feedbackData1 = {
    title: "ë„ì›€ë§",
    description: "ê·¸ë¦¼ì—ì„œ ë°”ë‚˜ë‚˜ì˜ í˜•íƒœê°€ ìž˜ ë“œëŸ¬ë‚˜ë„ë¡ ê³¡ì„ ì„ ìžì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•˜ì‹  ì ì´ ì¸ìƒì ìž…ë‹ˆë‹¤. ì£¼ì œë¥¼ ë°”ë‚˜ë‚˜ë¡œ ë” ëª…í™•í•˜ê²Œ í‘œí˜„í•˜ë ¤ë©´ ë‹¤ìŒì„ ê³ ë ¤í•´ ë³´ì„¸ìš” ë°”ë‚˜ë‚˜ì˜ ì–‘ ëë¶€ë¶„(ê¼­ì§€ì™€ ëë¶€ë¶„)ì„ ì•½ê°„ ì–´ë‘¡ê²Œ ì²˜ë¦¬í•˜ë©´ ì‹¤ì œ ë°”ë‚˜ë‚˜ì˜ ëŠë‚Œì„ ë” ì‚´ë¦´ ìˆ˜ ìžˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
  };

  const feedbackData2 = {
    title: "ë„ì›€ë§",
    description: "ê·¸ë¦¼ì—ì„œ ë°”ë‚˜ë‚˜ì˜ ì–‘ ëë¶€ë¶„(ê¼­ì§€ì™€ ëë¶€ë¶„)ì„ ì•½ê°„ ì–´ë‘¡ê²Œ ì²˜ë¦¬í•˜ì‹  ì ì´ ì •ë§ ë‹ë³´ìž…ë‹ˆë‹¤! ðŸŽ¨ ë°”ë‚˜ë‚˜ì˜ ì‹¤ì œê°ì„ í›Œë¥­ížˆ í‘œí˜„í•´ ì£¼ì…¨ê³ , ëë¶€ë¶„ì˜ ì–´ë‘ìš´ ë””í…Œì¼ì´ ì‹ ì„ í•œ ë°”ë‚˜ë‚˜ì˜ ëŠë‚Œì„ ë” ìƒë™ê° ìžˆê²Œ ì „ë‹¬í•˜ê³  ìžˆì–´ìš”. íŠ¹ížˆ ìƒ‰ìƒì˜ í†¤ ë³€í™”ê°€ ìžì—°ìŠ¤ëŸ¬ì›Œì„œ ê·¸ë¦¼ì— ê¹Šì´ë¥¼ ë”í•œ ì ì´ ì¸ìƒì ìž…ë‹ˆë‹¤. ðŸ˜Š"
  };

  const audioFiles = [
    '/canvasTutorial/eraser.wav',
    '/canvasTutorial/brushWidth.wav',
    '/canvasTutorial/colorPanel.wav',
    '/canvasTutorial/stepOne.wav',
    '/canvasTutorial/acceptFeedback.wav',
    '/canvasTutorial/fill.wav',
    '/canvasTutorial/specificDraw.wav',
    '/canvasTutorial/stepTwo.wav',
    '/canvasTutorial/acceptFeedback2.wav',
    '/canvasTutorial/save.wav',
  ];

  const playAudio = (index: number) => {
    console.log("index: ", index);
    if (playedAudios.has(index) || index >= audioFiles.length) return;
    
    dispatch({ type: 'ADD_TO_QUEUE', payload: audioFiles[index] });
    setPlayedAudios(prev => new Set([...prev, index]));
    const nextIndex = index + 1;
    setCurrentAudioIndex(nextIndex);
};

  const debouncedAudioPlay = useRef(
    debounce((currentIndex: number) => {
        playAudio(currentIndex);
    }, 5000)
  ).current;

  const handleChange = () => {
    onChange();
    debouncedAudioPlay(currentAudioIndex);
  };

  useEffect(() => {
    return () => {
      debouncedAudioPlay.cancel();
    };
  }, [debouncedAudioPlay]);

  useEffect(() => {
    const handleStepChange = async () => {
      if (step === 2) {
        setCurrentFeedback(feedbackData1);
        setIsPanelVisible(true);
        // await playAudio('4.wav');
      } else if (step === 3) {
        setCurrentFeedback(feedbackData2);
        setIsPanelVisible(true);
        // await playAudio('5.wav');
      } else {
        setIsPanelVisible(false);
      }
    };

    handleStepChange();
  }, [step]);

  useEffect(() => {
    if (!canvasContainerRef.current || !canvasRef.current) return;

    const newCanvas = new fabric.Canvas(canvasRef.current, {
      width: window.outerWidth,
      height: window.outerHeight,
      backgroundColor: "transparent"
    });

    setCanvas(newCanvas);

    newCanvas.freeDrawingBrush.width = brushWidth;
    newCanvas.isDrawingMode = true;
    newCanvas.renderAll();

    const handleResize = () => {
      newCanvas.setWidth(window.innerWidth);
      newCanvas.setHeight(window.innerHeight);
      newCanvas.renderAll();
    };

    window.addEventListener("resize", handleResize);

    const fetchImageMetaData = async () => {
      try {
        const response = await API.canvasApi.ImagemetaData({ sessionId: "your_session_id", topic: "your_topic" });
        setImageData(response.data);
      } catch (error) {
        console.error('Error fetching image metadata:', error);
      }
    };
    fetchImageMetaData();


    setImageData({
      title: "ë°”ë‚˜ë‚˜",
      description: "ë‹¬ì½¤í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§›ì„ ê°€ì§„ ë…¸ëž€ìƒ‰ì˜ ì—´ëŒ€ ê³¼ì¼ë¡œ, ê³¡ì„  ëª¨ì–‘ì˜ íŠ¹ì§•ì ì¸ í˜•íƒœë¥¼ ê°€ì§€ê³  ìžˆìŠµë‹ˆë‹¤.",
      image : "public/MockImage/ë©”íƒ€_ëª©_ë°ì´í„°.png"
    });

    return () => {
      newCanvas.dispose();
      window.removeEventListener("resize", handleResize);
    };
  }, [canvasRef, setCanvas]);

  const handleFinalSave = async () => {
    if (onFinalSave) {
      onFinalSave();
    }
  };

  const saveCanvasAsImage = async () => {
    if (!canvas) return;

    // ìº”ë²„ìŠ¤ì˜ ê°ì²´ í™•ì¸
    const objects = canvas.getObjects();
    if (objects.length === 0) {
      alert("ê·¸ë¦¼ì„ ê·¸ë ¤ì£¼ì„¸ìš”!");
      return;
    }

    const dataURL = makeFrame(canvas);

    if (step === 1) {
      await onUpload(dataURL, step);
      setStep(2);
      setIsPanelVisible(true);
    } else if (step === 2) {
      await onUpload(dataURL, step);
      setStep(3);
    } else if (step === 3) {
      setIsPanelVisible(false);
      await handleFinalSave();
    }
  };
  
  const handleMouseMove = (e: React.MouseEvent) => {
    if (isDragging) {
      const newX = e.clientX - offset.x;
      const newY = e.clientY - offset.y;
      setPanelPosition({ x: newX, y: newY });
    }
  };

  const handleMouseUp = () => {
    setIsDragging(false);
    handleChange();
  };

  const toggleImageCard = (e: React.MouseEvent) => {
    e.stopPropagation();
    setIsImageCardCollapsed(!isImageCardCollapsed);
  };

  const toggleFeedbackCard = (e: React.MouseEvent) => {
    e.stopPropagation();
    setIsFeedbackCardCollapsed(!isFeedbackCardCollapsed);
  };

  useEffect(() => {
    if (!isPlaying) {
      setOverlay(null);
      return;
    }

    const audioFileName = state.queue[0]?.split('/').pop()?.replace('.wav', '');
    setCurrentPlayingFile(audioFileName || null);

    switch (audioFileName) {
      case 'eraser':
        setOverlay('eraser');
        break;
      case 'brushWidth':
        setOverlay('brushWidth');
        break;
      case 'colorPanel':
        setOverlay('colorPanel');
        break;
      case 'stepOne':
        setOverlay('save');
        break;
      case 'fill':
        setOverlay('fill');
        break;
      case 'stepTwo':
        setOverlay('save');
        break;
      case 'save':
        setOverlay('save');
        break;
      default:
        setOverlay(null);
    }
  }, [isPlaying, state.queue]);

  useEffect(() => {
    console.log('Audio State:', {
      isPlaying,
      currentPlayingFile,
      overlay,
      queue: state.queue
    });
  }, [isPlaying, currentPlayingFile, overlay, state.queue]);

  return (
    <div 
      className={style.canvasContainer} 
      ref={canvasContainerRef} 
      onMouseMove={handleMouseMove} 
      onMouseUp={handleMouseUp}
    >
      <BannerSection onSave={saveCanvasAsImage} step={step} />
      <canvas ref={canvasRef} className={style.canvas} onTouchEnd={handleChange} id="mycanvas"/>
      {imageData && (
        <ImagePanelSection 
          imageData={imageData}
          isImageCardCollapsed={isImageCardCollapsed}
          toggleImageCard={toggleImageCard}
        />
      )}
      {currentFeedback && isPanelVisible && (
        <FeedbackSection 
          currentFeedback={currentFeedback}
          isFeedbackCardCollapsed={isFeedbackCardCollapsed}
          toggleFeedbackCard={toggleFeedbackCard}
        />
      )}
      {isPlaying && overlay && <Overlay type={overlay} isVisible={true} />}
    </div>
  );
};

export default CanvasSection;